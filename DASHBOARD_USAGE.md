# Metrics Dashboard Usage Guide

## Accessing the Dashboard

Your enhanced metrics dashboard is now ready at:

```
http://localhost:8000/web/metrics.html
```

Or if your API runs on a different port, replace `8000` with your port number.

## What's New in the Dashboard

### 1. **Cumulative Token Consumption (All Time)**

Located in the second section of the dashboard, this shows:

- **Total Tokens (All Time)** - Total tokens consumed since you started tracking (highlighted in gold)
- **Prompt Tokens** - Total input tokens sent to the LLM
- **Completion Tokens** - Total output tokens generated by the LLM
- **Total API Calls** - Number of API calls with the date of your first tracked call

**Use Case:** Track your total usage to monitor costs, estimate monthly expenses, or understand your chatbot's overall consumption patterns.

### 2. **Context Window Operations**

Shows how your chatbot manages its memory and context:

- **Total Events** - Number of context operations (clears, resets, trims)
- **Turns Cleared** - Conversation turns removed from context
- **Tokens Cleared** - Estimated tokens removed from memory
- **Affected Threads** - Number of conversation threads modified

**Event Breakdown:** Visual badges showing event types:
- üü¢ **new_thread** - New conversation started
- üü° **window_trim** - Context window size limit reached, old messages removed
- üî¥ **thread_clear** - Entire conversation cleared/reset
- üîµ **summary_compression** - Old turns compressed into summary
- üü£ **thread_switch** - User switched between conversation topics

**Use Case:** Understand when and why your chatbot is clearing context. If you see frequent window trims, consider increasing your memory window size or implementing better summarization.

### 3. **Recent Context Events Table**

A detailed log of recent context operations showing:
- Timestamp of the event
- Event type (with color-coded badge)
- Thread ID affected
- Number of turns and tokens cleared
- Reason for the operation

**Use Case:** Debug memory issues, understand conversation flow, track when users start new conversations.

## Dashboard Controls

### Time Range Selector
Choose the time window for your recent activity stats:
- Last Hour
- Last 6 Hours
- **Last 24 Hours** (default)
- Last Week

**Note:** Cumulative stats always show all-time totals, regardless of time range selection.

### Model Filter
Filter metrics by specific LLM model if you're using multiple models.

### Refresh Button
Manually refresh the dashboard. Auto-refreshes every 30 seconds.

## Understanding the Metrics

### Recent Activity (Last 24 Hours)
These are time-windowed stats showing only recent activity:
- Recent Tokens - Tokens used in the selected time range
- Recent Calls - API calls in the selected time range
- Avg Latency - Average response time
- Errors - Failed requests

### Model Comparison
Compare usage across different models (if using multiple models):
- Total calls per model
- Total tokens per model
- Average latency per model
- Error count per model

### Recent Calls
Detailed log of individual API calls with timestamps, tokens, latency, and status.

### Hourly Usage
Token consumption broken down by hour, useful for identifying usage patterns and peak times.

## Example Scenarios

### Scenario 1: Monitor Token Costs
1. Check **Cumulative Token Consumption** section
2. Note your total tokens (e.g., 3,350,000)
3. Calculate cost: `3,350,000 / 1000 * $0.XX per 1K tokens`
4. Track over time to project monthly expenses

### Scenario 2: Debug Memory Issues
1. Go to **Context Window Operations**
2. Check **Event Breakdown** - Are there too many `window_trim` events?
3. Review **Recent Context Events** table for specific threads with issues
4. Adjust `MEMORY_WINDOW_TURNS` in your config if needed

### Scenario 3: Analyze User Behavior
1. Check **Total Events** - How active are users?
2. Look at **new_thread** count - How many conversations started?
3. Compare with **thread_clear** count - Do users finish conversations or abandon them?
4. Use insights to improve conversation flow

## API Integration

The dashboard fetches data from:
```
GET /metrics?hours=24&include_cumulative=true&include_context_events=true
```

You can also access this data programmatically for custom dashboards or monitoring systems.

## Important Notes

### Token Count Accuracy
‚ö†Ô∏è **Current token counts are estimates** (word count √ó 1.3). This is a rough approximation.

For accurate token counting, see [METRICS_ENHANCEMENT_GUIDE.md](METRICS_ENHANCEMENT_GUIDE.md) for instructions on integrating actual tokenizer libraries.

### Context Event Tracking Requires Integration
Context window events will only appear if you integrate the tracking calls into your memory system. See [CONTEXT_TRACKING_EXAMPLE.py](Pipeline_chatbot_v1/tracking/CONTEXT_TRACKING_EXAMPLE.py) for integration examples.

Until integrated, the context events section will show zero events.

## Troubleshooting

### Dashboard shows "Loading..." forever
- Ensure your API is running
- Check browser console for errors
- Verify the API is accessible at `http://localhost:8000`
- Make sure the `/metrics` endpoint returns data

### Cumulative stats show zeros
- You may not have any tracked API calls yet
- Check that your chatbot is using the `UsageTrackingCallback`
- Verify the database exists at `data/llm_tracking.db`

### Context events show zeros
- Context event tracking requires manual integration
- Follow the examples in `CONTEXT_TRACKING_EXAMPLE.py`
- Add `tracker.log_context_event()` calls to your memory system

### Token counts seem wrong
- Token counts are currently estimated (word count √ó 1.3)
- Integrate a proper tokenizer for accurate counts
- See the enhancement guide for instructions

## Next Steps

1. **Start your API** and open the dashboard
2. **Use your chatbot** to generate some metrics
3. **Refresh the dashboard** to see cumulative token consumption
4. **Integrate context tracking** to see memory operations
5. **Monitor regularly** to track usage and costs

For detailed technical documentation, see:
- [METRICS_ENHANCEMENT_GUIDE.md](METRICS_ENHANCEMENT_GUIDE.md) - Complete API reference
- [CONTEXT_TRACKING_EXAMPLE.py](Pipeline_chatbot_v1/tracking/CONTEXT_TRACKING_EXAMPLE.py) - Integration examples
